---
title: "Laboratório 2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


É sabido que os períodos iniciais do curso de computação estão entre os mais difíceis de todo o curso. Entre os fatores que podem explicar isso, estão disciplinas que são consideradas difíceis para alunos recém saídos do ensino médio, como, por exemplo, Cálculo I, Álgebra Vetorial, P1 e LP1.

A porcentagem de evasão nos primeiros períodos também é bastante alta em relação a períodos posteriores, o que corrobora essa premissa. Isso nos leva a conjecturar que os alunos que apresentam bom desempenho nos períodos iniciais terão um bom desempenho no curso como um todo, ou seja, os alunos que foram bem na parte mais difícil do curso provavelmente irão bem também na parte menos difícil. Podemos colocar essa conjectura à prova por meio da seguinte pergunta:

O desempenho dos alunos nos dois primeiros períodos consegue explicar, em algum grau, seus desempenhos no curso como um todo?

Vamos tentar responder essa pergunta usando regressão linear. Vamos fazer isso quebrando a pergunta anterior nas seguintes perguntas:

-Um modelo de regressão múltipla com todas as variáveis é plausível para explicar a variação em y? Em que grau?

-Todas as variáveis são úteis para o modelo de regressão?

-Se a resposta para a pergunta anterior foi não, construa um novo modelo sem essas variáveis e o compare ao modelo com todas as variáveis (e.g. em termos de R2 e RSE).

-Analise os plots de resíduos de cada variável e veja se algum (um ou mais) deles indica não aleatoriedade dos erros.

-Que período consegue explicar melhor o desempenho final (primeiro ou segundo)?

-Use o melhor modelo encontrado para predizer o seu próprio desempenho e compare a predição com o seu CRA atual. Comente o resultado.

```{r, message=FALSE, warning=FALSE}
# Importando dados

library(readr)
library(dplyr)

graduados <- read_csv("graduados.csv", col_types = cols(matricula = col_character())) %>%
  mutate(matricula = as.factor(matricula))

graduados <- graduados %>%
  arrange(matricula)

# Limpando dados

graduados.clean <- graduados %>% filter(!is.na(media))

#Agora, vamos calcular o CRA dos alunos:

graduados.cra <- graduados.clean %>%
  group_by(matricula) %>%
  mutate(cra.contrib = media*creditos) %>%
  summarise(cra = sum(cra.contrib)/sum(creditos))

# Ajustar formato dos dados

library(reshape2)

graduados.model.input <- graduados.clean %>%
  group_by(matricula,disciplina)  %>%
  filter(media == max(media)) %>%
  ungroup() %>%
  select(matricula,disciplina,media) %>%
  mutate(disciplina = as.factor(gsub(" ",".",disciplina))) %>%
  dcast(matricula ~ disciplina, mean) %>%
  merge(graduados.cra)

# Criar tabelas com disciplinas do primeiro período

Disciplinas <- c("matricula", "Álgebra.Vetorial.e.Geometria.Analítica","Cálculo.Diferencial.e.Integral.I","Introdução.à.Computação","Laboratório.de.Programação.I","Leitura.e.Produção.de.Textos","Programação.I", "cra")
graduados.primeiro.per <- graduados.model.input[Disciplinas]

# Criar tabelas com disciplinas do segundo período
Disciplinas1 <- c("matricula", "Cálculo.Diferencial.e.Integral.II","Matemática.Discreta","Programação.II","Teoria.dos.Grafos","Fundamentos.de.Física.Clássica","Laboratório.de.Programação.II", "cra")
graduados.segundo.per <- graduados.model.input[Disciplinas1]

# Criar tabelas com disciplinas dos dois períodos
Disciplinas2<- c("matricula", "Cálculo.Diferencial.e.Integral.II","Matemática.Discreta","Programação.II","Teoria.dos.Grafos","Fundamentos.de.Física.Clássica","Laboratório.de.Programação.II", "Álgebra.Vetorial.e.Geometria.Analítica","Cálculo.Diferencial.e.Integral.I","Introdução.à.Computação","Laboratório.de.Programação.I","Leitura.e.Produção.de.Textos","Programação.I", "cra")
graduados.ambos.per <- graduados.model.input[Disciplinas2]

#limpando as tabelas

graduados.primeiro.per <- na.omit(graduados.primeiro.per)
graduados.segundo.per <- na.omit(graduados.segundo.per)
graduados.ambos.per <- na.omit(graduados.ambos.per)

### Removendo matricula
require(dplyr)
graduados.primeiro.per  <- graduados.primeiro.per  %>% select(-matricula)
graduados.segundo.per  <- graduados.segundo.per  %>% select(-matricula)
graduados.ambos.per  <- graduados.ambos.per  %>% select(-matricula)


```
## Examinando Histograma das variáveis

``` {r, echo=FALSE, message=FALSE, warning=FALSE}
require(reshape2)
require(ggplot2)

df <- melt(graduados.primeiro.per)
ggplot(df,aes(x = value)) +
  facet_wrap(~variable, scales = "free_x") +
  geom_histogram()

df1 <- melt(graduados.segundo.per)
ggplot(df1,aes(x = value)) +
  facet_wrap(~variable, scales = "free_x") +
  geom_histogram()

```

## Modelo com todas as variáveis

Inicialmente iremos utilizar a biblioteca corrplot para observar a correlação entre as disciplinas e o cra.

``` {r, echo=FALSE, message=FALSE, warning=FALSE}
library(corrplot)

colnames(graduados.ambos.per) <- c("Cálculo.II", "MatDis", "P2", "Grafos", "Física", "LP2", "Vetorial", "Calculo.I", "IC", "LP1", "LPT", "P1", "cra")

correlationMatrix <- cor(graduados.ambos.per)

corrplot(correlationMatrix, method="circle", type="lower", order="hclust")


```

Então escrevemos a equação da correlação linear:

``` {r, message=FALSE, warning=FALSE}

# Escrevendo a equação da correlação linear

lm3 <- lm(cra ~ Vetorial +
            Calculo.I + IC
          + LP1 + LPT + 
            P1 + Cálculo.II + MatDis
          + P2 + Grafos + Física
          + LP2, data= graduados.ambos.per)

summary(lm3)

```

Ao criar a função de correlação linear e utilizar a função summary observamos que o p-value mais baixo é o das variáveis de Matemática Discreta e Programação II.

O modelo com todas as variáveis possui um RSE de 0.5046 e um R² ajustado de 0.6474, portanto ele é plausível, porém possui algumas variáveis que não são úteis, desse modo temos que ele pode ser melhorado.

### Gráficos de Resíduo 

Pelo que pode ser observado nos gráficos de resíduo os erros são aleatórios.

``` {r, echo=FALSE, message=FALSE, warning=FALSE}

layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(lm3)

```

### Gráfico das Predições

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(caret)

predicoes3 = predict.lm(lm3,graduados.ambos.per)
cra3 <- graduados.ambos.per$cra

residuos3 = cra3 - predicoes3

axisRange = extendrange(c(cra3,predicoes3)) #deixando as variáveis na mesma escala

plot(cra3,predicoes3)
abline(0,1,col="blue",lty=2,lwd=2)

```



## Correlação do primeiro período

Inicialmente iremos usar o GGally para mostrar a correlação entre as variáveis

``` {r, echo=FALSE, message=FALSE, warning=FALSE}
library("GGally")
ggpairs(graduados.primeiro.per)

```

Podemos observar que as disciplinas com maior correlação com o cra são Introdução à Computação, Álgebra Vetorial, Cálculo I e Programação I. Em seguida escrevemos a equação da correlação linear.

``` {r,message=FALSE, warning=FALSE}

# Escrevendo a equação da correlação linear

lm1 <- lm(cra ~ Álgebra.Vetorial.e.Geometria.Analítica + Cálculo.Diferencial.e.Integral.I + Introdução.à.Computação + Laboratório.de.Programação.I + Leitura.e.Produção.de.Textos + Programação.I, data= graduados.primeiro.per)


summary(lm1)

```

Ao criar a função de correlação linear e utilizar a função summary observamos que o p-value mais baixo é o das variáveis Álgebra Linear, Introdução à Computação e Cálculo Diferencial e Integral I. Portanto é seguro afirmar que essas são as variáveis com maior relevância no modelo.

Também podemos observar o valor do R² ajustado que é ~0.54, o seu RSE é de 0.56. O modelo consegue explicar ~54%  da variável alvo CRA. 

### Gráficos de Resíduo 

Podemos observar com os gráficos de resíduo que os erros são de fato aleatórios.

``` {r, echo=FALSE, message=FALSE, warning=FALSE}

layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(lm1)

```

### Gráfico das Predições

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(caret)

predicoes = predict.lm(lm1,graduados.primeiro.per)
cra <- graduados.primeiro.per$cra

residuos = cra - predicoes

axisRange = extendrange(c(cra,predicoes)) #deixando as variáveis na mesma escala

plot(cra,predicoes)
abline(0,1,col="blue",lty=2,lwd=2)

```

## Correlação do segundo período

Inicialmente iremos visualizar a correlação entre as disciplinas e o cra com o auxílio do GGally

``` {r, echo=FALSE, message=FALSE, warning=FALSE}
library("GGally")
ggpairs(graduados.segundo.per)

```

Podemos observar que as disciplinas com maior correlação com o cra são Matemática Discreta, Programação II, Teoria dos Grafos e Cálculo II. Em seguida escrevemos a equação da correlação linear.

``` {r, message=FALSE, warning=FALSE}

# Escrevendo a equação da correlação linear

lm2 <- lm(cra ~ Cálculo.Diferencial.e.Integral.II + Matemática.Discreta + Programação.II + Teoria.dos.Grafos + Fundamentos.de.Física.Clássica + Laboratório.de.Programação.II, data= graduados.segundo.per)

summary(lm2)
```

Ao criar a função de correlação linear e utilizar a função summary observamos que o p-value mais baixo é o das variáveis Matemática Discreta, Programação II, Teoria dos Grafos. Portanto é seguro afirmar que essas são as variáveis com maior relevância no modelo.

Também vemos que seu R² ajustado é de 0.64 e seu RSE é 0.50.  

### Gráficos de Resíduo 

Visualizando os gráficos de resíduo podemos chegar a conclusão que os erros são de fato aleatórios.

``` {r, echo=FALSE, message=FALSE, warning=FALSE}

layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(lm2)

```

### Gráfico das Predições

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(caret)

predicoes2 = predict.lm(lm2,graduados.segundo.per)
cra2 <- graduados.segundo.per$cra

residuos2 = cra2 - predicoes2

axisRange = extendrange(c(cra2,predicoes2)) #deixando as variáveis na mesma escala

plot(cra2,predicoes2)
abline(0,1,col="blue",lty=2,lwd=2)

```

## Criando modelos melhores

Como nem todas as variáveis são úteis no modelo de regressão, para criar modelos melhores escolhemos as variáveis com maior relevância de cada período.

``` {r, message=FALSE, warning=FALSE}
# Novo modelo para o primeiro período

require(dplyr)

graduados.primeiro.per.novo  <- graduados.primeiro.per  %>% 
  select(-Leitura.e.Produção.de.Textos)

```

Então visualizamos a correlação entre as variáveis:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library("GGally")
ggpairs(graduados.primeiro.per.novo)

```

Abaixo definimos a correlação linear múltipla do novo modelo

```{r, message=FALSE, warning=FALSE}
lm1.novo <- lm(cra ~ Álgebra.Vetorial.e.Geometria.Analítica + Cálculo.Diferencial.e.Integral.I + Introdução.à.Computação + Programação.I + Laboratório.de.Programação.I, data= graduados.primeiro.per)


summary(lm1.novo)
```

O RSE é de 0.57 e o R² ajustado é aproximandamente 0.53, não houve melhora no modelo ao retirarmos a variável de Leitura e Produção de Textos, pois com esta variável inclusa temos R² ajustado sendo ~0.54, e o RSE igual a 0.56.

```{r, message=FALSE, warning=FALSE}
lm1.novo <- lm(cra ~ Álgebra.Vetorial.e.Geometria.Analítica + Cálculo.Diferencial.e.Integral.I + Introdução.à.Computação + Programação.I, data= graduados.primeiro.per)

summary(lm1.novo)
```

Se retirarmos outra variável que não possui correlação alta com o cra, como Laboratório de Programação I também observamos que não há melhora no modelo. Portanto, para analisar a correlação entre as notas do primeiro período e o cra o modelo que devemos usar é o inicialmente proposto.

## Modelo novo do segundo período

Selecionamos apenas as variáveis escolhidas como mais importantes.

``` {r, message=FALSE, warning=FALSE}
# Novo modelo para o segundo período

require(dplyr)

graduados.segundo.per.novo  <- graduados.segundo.per  %>% 
  select(-Cálculo.Diferencial.e.Integral.II,-Laboratório.de.Programação.II,-Fundamentos.de.Física.Clássica)

```

Então visualizamos a correlação entre as variáveis:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library("GGally")
ggpairs(graduados.segundo.per.novo)

```

Abaixo definimos a correlação linear múltipla do novo modelo

```{r, message=FALSE, warning=FALSE}
lm2.novo <- lm(cra ~ Matemática.Discreta + Programação.II + Teoria.dos.Grafos, data= graduados.segundo.per)

summary(lm2.novo)
```

O novo modelo possui um RSE de 0.4997 e um R² ajustado de 0.65, o valor do RSE é menor do que o modelo original e o valor do R² ajustado é superior ao original, portanto temos que esse modelo é melhor.

### Gráficos de Resíduo 

Com o auxílio destes gráficos verificamos que o erro realmente é aleatório.

``` {r, echo=FALSE, message=FALSE, warning=FALSE}

layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(lm2.novo)

```

### Gráfico das Predições

```{r, message=FALSE, warning=FALSE}
library(caret)

predicoes2.novo = predict.lm(lm2.novo,graduados.segundo.per.novo)
cra2.novo <- graduados.segundo.per.novo$cra

residuos2.novo = cra2.novo - predicoes2.novo

axisRange = extendrange(c(cra2.novo,predicoes2.novo)) #deixando as variáveis na mesma escala

plot(cra2.novo,predicoes2.novo)
abline(0,1,col="blue",lty=2,lwd=2)

```

## Modelo novo de ambos os períodos

Primeiro retiramos variáveis que consideramos irrelevantes, como Leitura e Produção de Textos e LP1.

``` {r, message=FALSE, warning=FALSE}

# Escrevendo a equação da correlação linear

lm3.novo <- lm(cra ~ Vetorial +
            Calculo.I + IC +
            P1 + Cálculo.II + MatDis
          + P2 + Grafos + Física
          + LP2, data= graduados.ambos.per)

summary(lm3.novo)

```

Temos que o RSE é igual a 0.509 e o R² ajustado é 0.6411, houve um ligeiro aumento do RSE e uma diminuição no R² ajustado, o outro modelo continua sendo melhor. Vamos deixar as variáveis com os menores p-values apenas e verificar o que acontece.

``` {r, message=FALSE, warning=FALSE}

# Escrevendo a equação da correlação linear

lm3.novo <- lm(cra ~ Vetorial + IC +
          + MatDis + P2 + Grafos, data= graduados.ambos.per)

summary(lm3.novo)

```

O novo RSE é de 0.4983 (< 0.5046) e o R² ajustado é de 0.6561 (> 0.6474), portanto esse modelo é melhor que o original.

### Gráfico de correlação

``` {r, echo=FALSE, message=FALSE, warning=FALSE}
library(corrplot)

graduados.ambos.per.novo <- graduados.ambos.per  %>% 
  select(-Calculo.I, -LP1, -LPT, 
            -P1, -Cálculo.II, -Física, -LP2)

correlationMatrix1 <- cor(graduados.ambos.per.novo)

corrplot(correlationMatrix1, method="color", type="lower", order="hclust", addCoef.col = "black")


```

### Gráficos de Resíduo 

Com o auxílio destes gráficos verificamos que o erro realmente é aleatório.

``` {r, echo=FALSE, message=FALSE, warning=FALSE}

layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(lm3.novo)

```

### Gráfico das Predições

```{r,echo=FALSE, message=FALSE, warning=FALSE}
library(caret)

predicoes3.novo = predict.lm(lm3.novo,graduados.ambos.per.novo)
cra3.novo <- graduados.ambos.per.novo$cra

residuos3.novo = cra3.novo - predicoes3.novo

axisRange = extendrange(c(cra3.novo,predicoes3.novo)) #deixando as variáveis na mesma escala

plot(cra3.novo,predicoes3.novo)
abline(0,1,col="blue",lty=2,lwd=2)

```

## Que período consegue explicar melhor o desempenho final?

Baseando-se nos valores de RSE e R² ajustado podemos afirmar que o segundo período pode explicar melhor o desempenho final.

## Usando o modelo
